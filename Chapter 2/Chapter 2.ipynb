{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notations\n",
    "- $m$ is the number of instances in the dataset \n",
    "- $\\textbf{x}^{(i)}$ is a vector of all the feature values (excluding the label) of the $i^{th}$ instance in the dataset, and $y^{(i)}$ is its label (the desired output value for that instance).\n",
    "- $\\textbf{X}$ is a matrix containing all the feature values (excluding labels) of all instances in the dataset. There is one row per instance and the $i^{th}$ row is equal to the transpose of $\\textbf{x}^{(i)}$, noted $(\\textbf{x}^{(i)})^T$\n",
    "- $h$ is prediction function, also called a *hypothesis*.\n",
    "- $\\hat{y}$ is the predicted value. $\\hat{y}^{(i)}=h(\\textbf{x}^{(i)})$\n",
    "\n",
    "We use lowercase italic font for scalar values (such as $m$ or $y^{(i)}$) and function names (such as $h$), lowercase bold font for vectors (such as $\\textbf{x}^{(i)}$), and uppercase bold font for matrices (such as $\\textbf{X}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements\n",
    "### RMSE (Root Mean Square Error)  \n",
    "It measures the standard deviation of the errors the system makes in its predictions.\n",
    "$$\\text{RMSE(}\\textbf{X}, h)=\\sqrt{\\frac{1}{m}\\sum_{i=1}^m(h(\\textbf{x}^{(i)})-y^{(i)})^2}$$\n",
    "\n",
    "### MAE (Mean Absolute Error)\n",
    "$$\\text{MAE(}\\textbf{X},h)=\\frac{1}{m}\\sum_{i=1}^m|h(\\textbf{x}^{(i)}-y^{(i)}|$$\n",
    "\n",
    "### Distance measures\n",
    "Various distance measures, or *norms*, between two vectors: the vector of predictions and the vector of target values.  \n",
    "$\\ell_2\\ norm$, noted $||\\cdot||_2$ (or just $||\\cdot||$), known as the *Euclidian norm* as well.  \n",
    "$\\ell_1\\ norm$, noted $||\\cdot||_1$, sometimes called the *Manhattan norm*.  \n",
    "More generally, the $\\ell_k\\ norm$ of a vector $\\textbf{v}$ containing $n$ elements is defined as $||\\textbf{v}||_k=(|v_0|^k+|v_1|^k+...+|v_n|^k)^{\\frac{1}{k}}$. $\\ell_0$ just gives the cardinality of the vector (i.e., the number of elements), and $\\ell_\\infty$ just gives the maximum absolute value in the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules and dependencies\n",
    "  \n",
    "\n",
    "```\n",
    "$ pip3 install --upgrade jupyter matplotlib numpy pandas scipy scikit-learn\n",
    "```\n",
    "\n",
    "Documentation:\n",
    "[Jupyter](https://jupyter.readthedocs.io/en/latest/) \n",
    "[Matplotlib](https://matplotlib.org) \n",
    "[NumPy](https://docs.scipy.org/doc/numpy/user/index.html#user) \n",
    "[Pandas](http://pandas.pydata.org/pandas-docs/stable/) \n",
    "[SciPy](http://docs.scipy.org/doc/scipy/reference/) \n",
    "[Scikit learn](http://scikit-learn.org/stable/documentation.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simply shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(data, test_ratio):\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]\n",
    "\n",
    "# train_set, test_set = split_train_test(housing, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method just pick some instances randomly and set them aside. Well, this works, but it is not perfect. If you run the program again, it will generate a different test set. Over time, you will get to see the whole dataset, which is what you want to avoid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fix random number generator's seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test_with_fixed_seed(data, test_ratio, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    shuffled_indices = np.random.permutation(len(data))\n",
    "    test_set_size = int(len(data) * test_ratio)\n",
    "    test_indices = shuffled_indices[:test_set_size]\n",
    "    train_indices = shuffled_indices[test_set_size:]\n",
    "    return data.iloc[train_indices], data.iloc[test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another option is to save the test set on the first run and then load it in subsequent runs. But both these solutions will break next time you fetch an updated dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_check(identifier, test_ratio, hash):\n",
    "    return hash(np.int64(identifier)).digest()[-1] < 256 * test_ratio\n",
    "\n",
    "def split_train_test_by_id(data, test_ratio, id_column, hash=hashlib.md5):\n",
    "    ids = data[id_column]\n",
    "    in_test_set = ids.apply(lambda id_: test_set_check(id_, test_ratio, hash))\n",
    "    return data.loc[~in_test_set], data.loc[in_test_set]\n",
    "\n",
    "# housing_with_id = housing.reset_index()      # adds an `index` column\n",
    "# train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"index\")\n",
    "\n",
    "# housing_with_id = housing[\"longitude\"] * 1000 + housing[\"latitude\"]\n",
    "# train_set, test_set = split_train_test_by_id(housing_with_id, 0.2, \"id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use each instance's identifier to decide whether or not it should go in the test set (assuming instances have a unique and immutable identifier).  \n",
    "However, the housing dataset does not have an identifier column. The simplest solution is to use the row index as the ID. In this way, you need to make sure that new data gets appended to the end of the dataset, and no row ever gets deleted.  \n",
    "You can try to use the most stable features to build a unique identifier. E.g, a district's latitude and longitude."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-Learn built-in functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(housing, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing[\"income_cat\"] = np.ceil(housing[\"median_income\"] / 1.5)\n",
    "housing[\"income_cat\"].where(housing[\"income_cat\"] < 5, 5.0, inplace=True)\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "    strat_train_set = housing.loc[train_index]\n",
    "    strat_test_set = housing.loc[test_index]\n",
    "    \n",
    "for set in (strat_train_set, strat_test_set):\n",
    "    set.drop([\"income_cat\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
